{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYNB0Fn00SXP",
        "outputId": "d27d88a2-fb87-4d6b-d4f4-9d9d73bec818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ReOfszu4g1Q",
        "outputId": "d124a8f1-087b-4c82-8fe2-ed5cbd0569b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Github/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhxV8GZE4z93",
        "outputId": "2fb03d9d-969d-4e0f-ad8d-506901506441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PINO_Applications' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b AHNO https://github.com/jaysulk/PINO_Applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kEc5Vy96Q7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af1a580-d003-4ed8-9e0e-3b116ddc4a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github/PINO_Applications\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Github/PINO_Applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uTDUSKj6nRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4501a3-fcd6-47d8-ffea-ecfe21de3611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting functorch\n",
            "  Downloading functorch-2.0.0-py2.py3-none-any.whl (2.1 kB)\n",
            "Collecting torch<2.1,>=2.0 (from functorch)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->functorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->functorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->functorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->functorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->functorch) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch<2.1,>=2.0->functorch)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0->functorch) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0->functorch) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0->functorch) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch<2.1,>=2.0->functorch)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=2.0->functorch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=2.0->functorch) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=40bd0c9818eb87a91e5f8b85095bb53cbb1a6cf84e4d633da27f6c4fc5c01a2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, functorch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed functorch-2.0.0 lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install functorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTG2fyCf64P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc1b862-d993-44d8-8fdc-da0dffd37a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Mat73\n",
            "  Downloading mat73-0.62-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from Mat73) (3.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from Mat73) (1.23.5)\n",
            "Installing collected packages: Mat73\n",
            "Successfully installed Mat73-0.62\n"
          ]
        }
      ],
      "source": [
        "!pip install Mat73"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU_CRUdgAJYE",
        "outputId": "e4d20277-f8f8-4792-e61f-fb4ce9e67c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (17.0.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Collecting torch>=1.7 (from timm)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m867.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7->timm)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.1.0 (from torch>=1.7->timm)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, timm\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "functorch 2.0.0 requires torch<2.1,>=2.0, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 timm-0.9.12 torch-2.1.0 triton-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b AHNO-transformer https://github.com/jaysulk/AFNO-transformer.git /content/drive/MyDrive/Github/AFNO-transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8HjMZwdAM6g",
        "outputId": "f2feb403-4c10-4211-80eb-49f8b6b787c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/MyDrive/Github/AFNO-transformer' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/drive/MyDrive/Github/AFNO-transformer/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM-gGmuAAVsv",
        "outputId": "d1bab70f-b0bc-44b9-9b25-95b79777da2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/Github/AFNO-transformer\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: afno\n",
            "  Building wheel for afno (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afno: filename=afno-0.0.1-py3-none-any.whl size=16040 sha256=8903d23b22b21653b60595d26a6392450a621b4f4f1017e0ac54cf23dce5dc7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/48/0f/87c770d240c74cb454027fb3d5af919cb6ed10857b9caf1bda\n",
            "Successfully built afno\n",
            "Installing collected packages: afno\n",
            "Successfully installed afno-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from afno import AFNO1D,AFNO2D"
      ],
      "metadata": {
        "id": "ldmW0TpeARNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkYcCZ9w6-I1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "486b5833-6900-4468-9c56-bd2820af21c5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "%matplotlib notebook\n",
        "from argparse import ArgumentParser\n",
        "import yaml\n",
        "import os\n",
        "import torch\n",
        "# from torch import vmap\n",
        "from functorch import vmap, grad\n",
        "\n",
        "from models import FNN2d, FNN2d_AD\n",
        "from train_utils import Adam\n",
        "\n",
        "from solver.BurgersEq import BurgersEq1D\n",
        "import traceback\n",
        "\n",
        "import scipy.io\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import imageio\n",
        "\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "from train_utils.utils import get_grid, save_checkpoint, torch2dgrid, load_checkpoint, load_config, update_config\n",
        "from train_utils.losses import LpLoss\n",
        "from train_utils.datasets import DataLoader1D\n",
        "from solver.my_random_fields import GRF_Mattern\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "try:\n",
        "    import wandb\n",
        "except ImportError:\n",
        "    wandb = None\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "afno = AFNO1D(hidden_size=128, num_blocks=4, sparsity_threshold=0.01,\n",
        "                          hard_thresholding_fraction=1, hidden_size_factor=1)"
      ],
      "metadata": {
        "id": "zUWJ27Fy_RhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI0YSHYV7Fee"
      },
      "outputs": [],
      "source": [
        "def FDM_Burgers(u, D=1, nu=0.01):\n",
        "    batchsize = u.size(0)\n",
        "    nt = u.size(1)\n",
        "    nx = u.size(2)\n",
        "\n",
        "    # Reshape for AFNO1D\n",
        "    u = u.reshape(batchsize * nt, nx)\n",
        "    u = afno(u)\n",
        "    u = u.reshape(batchsize, nt, nx)\n",
        "    u2 = u**2\n",
        "    dt = D / (nt-1)\n",
        "    dx = D / (nx)\n",
        "\n",
        "    u_h = torch.fft.fft(u, dim=2)\n",
        "    u2_h = torch.fft.fft(u2, dim=2)\n",
        "    k_max = nx//2\n",
        "    k_x = torch.cat((torch.arange(start=0, end=k_max, step=1, device=u.device),\n",
        "                     torch.arange(start=-k_max, end=0, step=1, device=u.device)), 0).reshape(1,1,nx)\n",
        "    ux_h = 2j *np.pi*k_x*u_h\n",
        "    u2x_h = 2j *np.pi*k_x*u2_h\n",
        "    uxx_h = 2j *np.pi*k_x*ux_h\n",
        "    ux = torch.fft.irfft(ux_h[:, :, :k_max+1], dim=2, n=nx)\n",
        "    u2x = torch.fft.irfft(u2x_h[:, :, :k_max+1], dim=2, n=nx)\n",
        "    uxx = torch.fft.irfft(uxx_h[:, :, :k_max+1], dim=2, n=nx)\n",
        "    ut = (u[:, 2:, :] - u[:, :-2, :]) / (2 * dt)\n",
        "    Du = ut + (0.5*u2x - nu*uxx)[:,1:-1,:]\n",
        "    return Du\n",
        "\n",
        "def PINO_loss_Burgers(u, u0, nu=0.01):\n",
        "    batchsize = u.size(0)\n",
        "    nt = u.size(1)\n",
        "    nx = u.size(2)\n",
        "\n",
        "    u = u.reshape(batchsize, nt, nx)\n",
        "\n",
        "    index_t = torch.zeros(nx,).long()\n",
        "    index_x = torch.tensor(range(nx)).long()\n",
        "    boundary_u = u[:, index_t, index_x]\n",
        "    loss_u = F.mse_loss(boundary_u, u0)\n",
        "\n",
        "    Du = FDM_Burgers(u, nu=nu)[:, :, :]\n",
        "    f = torch.zeros(Du.shape, device=u.device)\n",
        "    loss_f = F.mse_loss(Du, f)\n",
        "\n",
        "    return loss_u, loss_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT96s8h6-Bqf"
      },
      "outputs": [],
      "source": [
        "def train_Burgers(model,\n",
        "                  train_loader,\n",
        "                  optimizer,\n",
        "                  scheduler,\n",
        "                  config,\n",
        "                  rank=0,\n",
        "                  log=False,\n",
        "                  project='PINO-2d-default',\n",
        "                  group='default',\n",
        "                  tags=['default'],\n",
        "                  use_tqdm=True):\n",
        "    if rank == 0 and wandb and log:\n",
        "        run = wandb.init(project=project,\n",
        "                         entity='shawngr2',\n",
        "                         group=group,\n",
        "                         config=config,\n",
        "                         tags=tags, reinit=True,\n",
        "                         settings=wandb.Settings(start_method=\"fork\"))\n",
        "\n",
        "    data_weight = config['train']['xy_loss']\n",
        "    f_weight = config['train']['f_loss']\n",
        "    ic_weight = config['train']['ic_loss']\n",
        "    nu = config['data']['nu']\n",
        "    ckpt_freq = config['train']['ckpt_freq']\n",
        "\n",
        "    model.train()\n",
        "    myloss = LpLoss(size_average=True)\n",
        "\n",
        "    pbar = range(config['train']['epochs'])\n",
        "    if use_tqdm:\n",
        "        pbar = tqdm(pbar, dynamic_ncols=True, smoothing=0.1)\n",
        "\n",
        "    for e in pbar:\n",
        "        model.train()\n",
        "        train_pino = 0.0\n",
        "        data_l2 = 0.0\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(rank), y.to(rank)\n",
        "            out = model(x).reshape(y.shape)\n",
        "            data_loss = myloss(out, y)\n",
        "\n",
        "            loss_u, loss_f = PINO_loss_Burgers(out, x[:, 0, :, 0], nu=nu)\n",
        "            total_loss = loss_u * ic_weight + loss_f * f_weight + data_loss * data_weight\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            data_l2 += data_loss.item()\n",
        "            train_pino += loss_f.item()\n",
        "            train_loss += total_loss.item()\n",
        "        scheduler.step()\n",
        "        data_l2 /= len(train_loader)\n",
        "        train_pino /= len(train_loader)\n",
        "        train_loss /= len(train_loader)\n",
        "        if use_tqdm:\n",
        "            pbar.set_description(\n",
        "                (\n",
        "                    f'Epoch {e}, train loss: {train_loss:.5f} '\n",
        "                    f'train f error: {train_pino:.5f}; '\n",
        "                    f'data l2 error: {data_l2:.5f}'\n",
        "                )\n",
        "            )\n",
        "        if wandb and log:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    'Train f error': train_pino,\n",
        "                    'Train L2 error': data_l2,\n",
        "                    'Train loss': train_loss,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        if e % ckpt_freq == 0:\n",
        "            save_checkpoint(config['train']['save_dir'],\n",
        "                            config['train']['save_name'].replace('.pt', f'_{e}.pt'),\n",
        "                            model, optimizer)\n",
        "    save_checkpoint(config['train']['save_dir'],\n",
        "                    config['train']['save_name'],\n",
        "                    model, optimizer)\n",
        "    print('Done!')\n",
        "# Additional code such as save_checkpoint and LpLoss should be defined or imported as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "879O3R9Q-Snf"
      },
      "outputs": [],
      "source": [
        "def eval_Burgers(model,\n",
        "                 dataloader,\n",
        "                 config,\n",
        "                 device,\n",
        "                 use_tqdm=True):\n",
        "    model.eval()\n",
        "    myloss = LpLoss(size_average=True)\n",
        "    nu = config['data']['nu']\n",
        "    if use_tqdm:\n",
        "        pbar = tqdm(dataloader, dynamic_ncols=True, smoothing=0.05)\n",
        "    else:\n",
        "        pbar = dataloader\n",
        "\n",
        "    test_err = []\n",
        "    f_err = []\n",
        "    with torch.no_grad():\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x).reshape(y.shape)\n",
        "            data_loss = myloss(out, y)\n",
        "\n",
        "            loss_u, f_loss = PINO_loss_Burgers(out, x[:, 0, :, 0], nu=nu)\n",
        "            test_err.append(data_loss.item())\n",
        "            f_err.append(f_loss.item())\n",
        "\n",
        "    mean_f_err = np.mean(f_err)\n",
        "    std_f_err = np.std(f_err, ddof=1) / np.sqrt(len(f_err))\n",
        "\n",
        "    mean_err = np.mean(test_err)\n",
        "    std_err = np.std(test_err, ddof=1) / np.sqrt(len(test_err))\n",
        "\n",
        "    print(f'==Averaged relative L2 error mean: {mean_err}, std error: {std_err}==\\n'\n",
        "          f'==Averaged equation error mean: {mean_f_err}, std error: {std_f_err}==')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN8Tb9Ij-VDH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "21ff93e4-27da-43c2-89a5-0f0cdca91387"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'data': {'name': 'Burgers-0003',\n",
              "  'total_num': 100,\n",
              "  'n_train': 90,\n",
              "  'n_test': 10,\n",
              "  'nx': 128,\n",
              "  'nt': 100,\n",
              "  'sub': 1,\n",
              "  'sub_t': 1,\n",
              "  'nu': 0.01},\n",
              " 'model': {'layers': [16, 24, 24, 32, 32],\n",
              "  'modes1': [15, 12, 9, 9],\n",
              "  'modes2': [15, 12, 9, 9],\n",
              "  'fc_dim': 128,\n",
              "  'activation': 'gelu'},\n",
              " 'train': {'batchsize': 20,\n",
              "  'epochs': 500,\n",
              "  'milestones': [100, 200, 300, 400, 500],\n",
              "  'base_lr': 0.001,\n",
              "  'scheduler_gamma': 0.5,\n",
              "  'ic_loss': 5.0,\n",
              "  'f_loss': 1.0,\n",
              "  'xy_loss': 5.0,\n",
              "  'save_dir': 'Burgers',\n",
              "  'save_name': 'Burgers-0003.pt',\n",
              "  'ckpt': 'checkpoints/Burgers/Burgers-0003.pt',\n",
              "  'ckpt_freq': 100},\n",
              " 'log': {'project': 'PINO-Burgers', 'group': 'Burgers-0003'},\n",
              " 'test': {'batchsize': 1, 'ckpt': 'checkpoints/Burgers/Burgers-0003.pt'}}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "config_file = 'configs/custom/burgers-0003.yaml'\n",
        "config = load_config(config_file)\n",
        "display(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eFmreWu-X9W"
      },
      "outputs": [],
      "source": [
        "Nsamples = config['data']['total_num']\n",
        "N = config['data']['nx']\n",
        "Nt0 = config['data']['nt']\n",
        "nu = config['data']['nu']\n",
        "sub_x = config['data']['sub']\n",
        "sub_t = config['data']['sub_t']\n",
        "Nx = N // sub_x\n",
        "Nt = Nt0 // sub_t + 1\n",
        "dim = 1\n",
        "l = 0.1\n",
        "L = 1.0\n",
        "sigma = 0.5 #2.0\n",
        "Nu = None # 2.0\n",
        "dt = 1.0e-4\n",
        "tend = 1.0\n",
        "save_int = int(tend/dt/Nt)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqupI2-6-at-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b985ec1-c2a6-48cf-d43c-2429457c7b72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qlvo8z2X-dYd"
      },
      "outputs": [],
      "source": [
        "#grf = GRF_Mattern(dim, N, length=L, nu=Nu, l=l, sigma=sigma, boundary=\"periodic\", device=device)\n",
        "#U0 = grf.sample(Nsamples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjJeLfGglmoV"
      },
      "outputs": [],
      "source": [
        "with open('../../T0.pkl', 'rb') as f:\n",
        "  U0 = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-xOH67x-5_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173c9cd6-af7d-4c31-ce51-dabdd79cb857"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "U0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-EgFBHE-7oW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a68d166-cf19-4bc5-c42d-4927ef8350ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "nu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22XnsW6w-9rG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1f527f-42e9-44fd-e4a0-a1f9693d6f56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
            "  warn_deprecated('vmap', 'torch.vmap')\n"
          ]
        }
      ],
      "source": [
        "burgers_eq = BurgersEq1D(Nx=Nx, nu=nu, dt=dt, device=device)\n",
        "save_interval = int(1e-2/dt)\n",
        "U = vmap(burgers_eq.burgers_driver, in_dims=(0, None))(U0, save_interval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj4mILUn_ALe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "96f2bf4c-095a-4374-9b0c-de4759e3186e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([100, 101, 128])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([100, 128])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "a = U0.cpu().float()\n",
        "u = U.cpu().float()\n",
        "display(u.shape,a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRTkzseR_C_f"
      },
      "outputs": [],
      "source": [
        "dataset = DataLoader1D(a, u, config['data']['nx'], config['data']['nt'])\n",
        "train_loader = dataset.make_loader(config['data']['n_train'], config['train']['batchsize'], start=0, train=True)\n",
        "test_loader = dataset.make_loader(config['data']['n_test'], config['test']['batchsize'], start=config['data']['n_train'], train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTaSq2WH_GBn"
      },
      "outputs": [],
      "source": [
        "model = FNN2d(modes1=config['model']['modes1'],\n",
        "              modes2=config['model']['modes2'],\n",
        "              fc_dim=config['model']['fc_dim'],\n",
        "              layers=config['model']['layers'],\n",
        "              activation=config['model']['activation'],\n",
        "             ).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgVmKCtp_IKO"
      },
      "outputs": [],
      "source": [
        "log = False\n",
        "\n",
        "optimizer = Adam(model.parameters(), betas=(0.9, 0.999),lr=config['train']['base_lr'])\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                 milestones=config['train']['milestones'],\n",
        "                                                 gamma=config['train']['scheduler_gamma'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxiW3U3m_KBG"
      },
      "outputs": [],
      "source": [
        "#load_checkpoint(model, ckpt_path=config['train']['ckpt'], optimizer=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5SJFHGZ_NLm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "aa631e2e-9b8a-4a84-843b-bc01fbabaaf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/500 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[20, 56, 56, 64]' is invalid for input of size 4136960",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-f02c5c906ba0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_Burgers(model,\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-f7775841fd8e>\u001b[0m in \u001b[0;36mtrain_Burgers\u001b[0;34m(model, train_loader, optimizer, scheduler, config, rank, log, project, group, tags, use_tqdm)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mdata_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Github/PINO_Applications/models/fourier2d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Apply AFNO2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mx_afno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx_afno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_afno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_afno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/afno/afno2d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m#    H, W = spatial_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdht2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[20, 56, 56, 64]' is invalid for input of size 4136960"
          ]
        }
      ],
      "source": [
        "train_Burgers(model,\n",
        "              train_loader,\n",
        "              optimizer,\n",
        "              scheduler,\n",
        "              config,\n",
        "              rank=0,\n",
        "              log=log,\n",
        "              project=config['log']['project'],\n",
        "              group=config['log']['group'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VCEwh1xKdPO"
      },
      "outputs": [],
      "source": [
        "eval_Burgers(model, test_loader, config, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRRLJJ44LgLe"
      },
      "outputs": [],
      "source": [
        "Nx = config['data']['nx']\n",
        "Nt = config['data']['nt'] + 1\n",
        "N = config['data']['n_test']\n",
        "model.eval()\n",
        "test_x = np.zeros((N,Nt,Nx,3))\n",
        "preds_y = np.zeros((N,Nt,Nx))\n",
        "test_y = np.zeros((N,Nt,Nx))\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        data_x, data_y = data\n",
        "        data_x, data_y = data_x.to(device), data_y.to(device)\n",
        "        pred_y = model(data_x).reshape(data_y.shape)\n",
        "        test_x[i] = data_x.cpu().numpy()\n",
        "        test_y[i] = data_y.cpu().numpy()\n",
        "        preds_y[i] = pred_y.cpu().numpy()\n",
        "#     data_loss = myloss(out, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnuHL0vDLjk-"
      },
      "outputs": [],
      "source": [
        "Nx = config['data']['nx']\n",
        "Nt = config['data']['nt'] + 1\n",
        "N = config['data']['n_test']\n",
        "model.eval()\n",
        "test_x = np.zeros((N,Nt,Nx,3))\n",
        "preds_y = np.zeros((N,Nt,Nx))\n",
        "test_y = np.zeros((N,Nt,Nx))\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        data_x, data_y = data\n",
        "        data_x, data_y = data_x.to(device), data_y.to(device)\n",
        "        pred_y = model(data_x).reshape(data_y.shape)\n",
        "        test_x[i] = data_x.cpu().numpy()\n",
        "        test_y[i] = data_y.cpu().numpy()\n",
        "        preds_y[i] = pred_y.cpu().numpy()\n",
        "#     data_loss = myloss(out, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwxow5auLovm"
      },
      "outputs": [],
      "source": [
        "data_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al5SeByKLq6m"
      },
      "outputs": [],
      "source": [
        "use_train_data = False\n",
        "padding = 5\n",
        "batch_size = config['test']['batchsize']\n",
        "Nx = config['data']['nx']\n",
        "# Ny = config['data']['nx']\n",
        "Nt = config['data']['nt'] + 1\n",
        "Ntest = config['data']['n_test']\n",
        "Ntrain = config['data']['n_train']\n",
        "loader = test_loader\n",
        "if use_train_data:\n",
        "    Ntest = Ntrain\n",
        "    loader = train_loader\n",
        "# in_dim = config['model']['in_dim']\n",
        "# out_dim = config['model']['out_dim']\n",
        "\n",
        "model.eval()\n",
        "# model.to('cpu')\n",
        "test_x = np.zeros((Ntest,Nt,Nx,3))\n",
        "preds_y = np.zeros((Ntest,Nt,Nx))\n",
        "test_y = np.zeros((Ntest,Nt,Nx))\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(loader):\n",
        "#     for i, data in enumerate(train_loader):\n",
        "        data_x, data_y = data\n",
        "        data_x, data_y = data_x.to(device), data_y.to(device)\n",
        "#         data_x_pad = F.pad()\n",
        "#         display(data_x.shape)\n",
        "        data_x_pad = F.pad(data_x, (0, 0, 0, 0, 0, padding), \"constant\", 0)\n",
        "        pred_y_pad = model(data_x_pad).reshape(batch_size, Nt + padding, Nx)\n",
        "#         out = out[..., :-padding, :]\n",
        "#         pred_y_pad = model(data_x_pad).reshape(batch_size, Nx, Ny, Nt + padding, out_dim)\n",
        "        pred_y = pred_y_pad[..., :-padding, :].reshape(data_y.shape)\n",
        "#         pred_y = model(data_x).reshape(data_y.shape)\n",
        "        test_x[i] = data_x.cpu().numpy()\n",
        "        test_y[i] = data_y.cpu().numpy()\n",
        "#         test_y0[i] = data_x[..., 0, -out_dim:].cpu().numpy() # same way as in training code\n",
        "        preds_y[i] = pred_y.cpu().numpy()\n",
        "#     data_loss = myloss(out, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s_gVtaFLuKW"
      },
      "outputs": [],
      "source": [
        "len(preds_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8_rTWA6L5uX"
      },
      "outputs": [],
      "source": [
        "key = 0\n",
        "pred = preds_y[key]\n",
        "true = test_y[key]\n",
        "\n",
        "\n",
        "a = test_x[key]\n",
        "Nt, Nx, _ = a.shape\n",
        "u0 = a[0,:,0]\n",
        "T = a[:,:,2]\n",
        "X = a[:,:,1]\n",
        "x = X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5Dds0tCLwMW"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(24,5))\n",
        "plt.subplot(1,4,1)\n",
        "\n",
        "plt.plot(x, u0)\n",
        "plt.xlabel('$x$')\n",
        "plt.ylabel('$u$')\n",
        "plt.title('Intial Condition $u(x)$')\n",
        "plt.xlim([0,1])\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(1,4,2)\n",
        "# plt.pcolor(XX,TT, S_test, cmap='jet')\n",
        "plt.pcolormesh(X, T, true, cmap='jet', shading='gouraud')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$x$')\n",
        "plt.ylabel('$t$')\n",
        "plt.title(f'Exact $s(x,t)$')\n",
        "plt.tight_layout()\n",
        "plt.axis('square')\n",
        "\n",
        "plt.subplot(1,4,3)\n",
        "# plt.pcolor(XX,TT, S_pred, cmap='jet')\n",
        "plt.pcolormesh(X, T, pred, cmap='jet', shading='gouraud')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$x$')\n",
        "plt.ylabel('$t$')\n",
        "plt.title(f'Predict $s(x,t)$')\n",
        "plt.axis('square')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(1,4,4)\n",
        "# plt.pcolor(XX,TT, S_pred - S_test, cmap='jet')\n",
        "plt.pcolormesh(X, T, pred - true, cmap='jet', shading='gouraud')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$x$')\n",
        "plt.ylabel('$t$')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "plt.axis('square')\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2gxeyLPLy4n"
      },
      "outputs": [],
      "source": [
        "def save_data(data_path, test_x, test_y, preds_y):\n",
        "    data_dir, data_filename = os.path.split(data_path)\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "    np.savez(data_path, test_x=test_x, test_y=test_y, preds_y=preds_y)\n",
        "\n",
        "def load_data(data_path):\n",
        "    data = np.load(data_path)\n",
        "    test_x = data['test_x']\n",
        "    test_y = data['test_y']\n",
        "    preds_y = data['preds_y']\n",
        "    return test_x, test_y, preds_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wxXMv3qL-Ce"
      },
      "outputs": [],
      "source": [
        "data_dir = 'data/Burgers1D'\n",
        "data_filename = 'data.npz'\n",
        "data_path = os.path.join(data_dir, data_filename)\n",
        "# os.makedirs(data_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtmMulcdMALW"
      },
      "outputs": [],
      "source": [
        "save_data(data_path, test_x, test_y, preds_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVHNRsFGMB9W"
      },
      "outputs": [],
      "source": [
        "test_x, test_y, preds_y = load_data(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nPko9CsMDwV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def plot_predictions(key, test_x, test_y, preds_y, print_index=False, save_path=None, font_size=None):\n",
        "    if font_size is not None:\n",
        "        plt.rcParams.update({'font.size': font_size})\n",
        "    pred = preds_y[key]\n",
        "    true = test_y[key]\n",
        "\n",
        "    a = test_x[key]\n",
        "    Nt, Nx, _ = a.shape\n",
        "    u0 = a[0,:,0]\n",
        "    T = a[:,:,2]\n",
        "    X = a[:,:,1]\n",
        "    x = X[0]\n",
        "\n",
        "    # Plot\n",
        "    fig = plt.figure(figsize=(23,5))\n",
        "\n",
        "    # Intial Condition\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.plot(x, u0)\n",
        "    plt.xlabel('$x$')\n",
        "    plt.ylabel('$u$')\n",
        "    plt.title('Intial Condition $u(x)$')\n",
        "    plt.xlim([0,1])\n",
        "    plt.ylim([-0.6,0.6])\n",
        "    plt.text(0.05, 0.9, 'a', transform=plt.gca().transAxes)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Exact\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.pcolormesh(X, T, true, cmap='bwr', shading='gouraud')\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.mappable.set_clim(-0.6, 0.6)\n",
        "    plt.xlabel('$x$')\n",
        "    plt.ylabel('$t$')\n",
        "    plt.title(f'Exact $u(x,t)$')\n",
        "    plt.axis('square')\n",
        "    plt.text(0.05, 0.9, 'b', transform=plt.gca().transAxes)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Predict\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.pcolormesh(X, T, pred, cmap='bwr', shading='gouraud')\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.mappable.set_clim(-0.6, 0.6)\n",
        "    plt.xlabel('$x$')\n",
        "    plt.ylabel('$t$')\n",
        "    plt.title(f'Predict $u(x,t)$')\n",
        "    plt.axis('square')\n",
        "    plt.text(0.05, 0.9, 'c', transform=plt.gca().transAxes)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Absolute Error\n",
        "    my_object = np.abs(pred - true)\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.pcolormesh(X, T, my_object, cmap='hot', shading='gouraud')\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.mappable.set_clim(0, 0.1)\n",
        "    plt.xlabel('$x$')\n",
        "    plt.ylabel('$t$')\n",
        "    plt.title('Absolute Error')\n",
        "    plt.axis('square')\n",
        "    plt.text(0.05, 0.9, 'd', color='white', transform=plt.gca().transAxes)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path is not None:\n",
        "        plt.savefig(f'{save_path}.png', bbox_inches='tight')\n",
        "        with open(f'{save_path}.pkl', 'wb') as f:\n",
        "            pickle.dump(my_object, f)\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKgKrct_MG_1"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "figures_dir = '../../Burgers1DAFNO/figures/'\n",
        "os.makedirs(figures_dir, exist_ok=True)\n",
        "font_size = 12\n",
        "for key in range(len(preds_y)):\n",
        "    save_path = os.path.join(figures_dir, f'Burgers1D_{key}')\n",
        "    plot_predictions(key, test_x, test_y, preds_y, print_index=True, save_path=save_path, font_size=font_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdSVBqIZMJSW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvpmst1RRhz2tsdC/d9tEy"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}